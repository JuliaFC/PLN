{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4c88772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4608557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20,000 Leagues Under the Sea\n",
      "20,000 Leagues Under the Sea\n",
      "20,000 Leagues Under the Sea\n",
      "20,000 Leagues Under the Sea\n",
      "20,000 Leagues Under the Sea\n",
      "20,000 Leagues Under the Sea\n",
      "13\n",
      "13 Going on 30\n",
      "13 Going on 30\n",
      "13 Going on 30\n",
      "13\n",
      "13 Rue Madeleine\n",
      "10\n",
      "10 Things I Hate About You\n",
      "10 Things I Hate About You\n",
      "10 Things I Hate About You\n",
      "10 Things I Hate About You\n",
      "10 Things I Hate About You\n",
      "2\n",
      "2 Fast 2 Furious\n",
      "2\n",
      "2 Fast 2 Furious\n",
      "100 Rifles\n",
      "100 Rifles\n",
      "1\n",
      "10\n",
      "8½\n",
      "51\n",
      "2\n",
      "2\n",
      "16 to Life\n",
      "16 to Life\n",
      "3\n",
      "88 Minutes\n",
      "88 Minutes\n",
      "2\n",
      "2\n",
      "3\n",
      "3 Idiots\n",
      "13\n",
      "2-Headed Shark Attack\n",
      "2-Headed Shark Attack\n",
      "1900\n",
      "20,000 Leagues Under the Sea\n",
      "20,000 Leagues Under the Sea\n",
      "20,000 Leagues Under the Sea\n",
      "20,000 Leagues Under the Sea\n",
      "20,000 Leagues Under the Sea\n",
      "20,000 Leagues Under the Sea\n",
      "2\n",
      "100 Feet\n",
      "100 Feet\n",
      "16 Years of Alcohol\n",
      "16 Years of Alcohol\n",
      "16 Years of Alcohol\n",
      "16 Years of Alcohol\n",
      "1984\n",
      "9\n",
      "2000\n",
      "9\n",
      "3\n",
      "102 Dalmatians\n",
      "102 Dalmatians\n",
      "3\n",
      "2\n",
      "8 Mile\n",
      "8 Mile\n",
      "1929\n",
      "1935\n",
      "2\n",
      "1408\n",
      "4\n",
      "3\n",
      "3\n",
      "3 Strikes\n",
      "12\n",
      "2\n",
      "31 North 62 East\n",
      "31 North 62 East\n",
      "31 North 62 East\n",
      "2\n",
      "2\n",
      "21\n",
      "21 Jump Street\n",
      "21 Jump Street\n",
      "4\n",
      "2\n",
      "2\n",
      "12\n",
      "12 Years a Slave\n",
      "12 Years a Slave\n",
      "12 Years a Slave\n",
      "1918\n",
      "360\n",
      "2000\n",
      "12\n",
      "13\n",
      "13 Ghosts\n",
      "16 to Life\n",
      "16 to Life\n",
      "99 Homes\n",
      "99 Homes\n",
      "9\n",
      "12\n",
      "12 Dates of Christmas\n",
      "12 Dates of Christmas\n",
      "12 Dates of Christmas\n",
      "13\n",
      "13 Tzameti\n",
      "2\n",
      "1984\n",
      "2\n",
      "2\n",
      "3\n",
      "3 Godfathers\n",
      "2\n",
      "3\n",
      "12\n",
      "12 Angry Men\n",
      "12 Angry Men\n",
      "48 Shades\n",
      "48 Shades\n",
      "10\n",
      "10\n",
      "10 MPH\n",
      "2-Headed Shark Attack\n",
      "2-Headed Shark Attack\n",
      "40 Guns to Apache Pass\n",
      "40 Guns to Apache Pass\n",
      "40 Guns to Apache Pass\n",
      "40 Guns to Apache Pass\n",
      "99 Homes\n",
      "99 Homes\n",
      "360\n",
      "2000\n",
      "2\n",
      "3\n",
      "96 Minutes\n",
      "96 Minutes\n",
      "13\n",
      "2\n",
      "2\n",
      "2 Days in Paris\n",
      "2 Days in Paris\n",
      "4\n",
      "3\n",
      "700 Sundays\n",
      "700 Sundays\n",
      "711 Ocean Drive\n",
      "711 Ocean Drive\n",
      "2\n",
      "21\n",
      "9\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2 Days in New York\n",
      "2 Days in New York\n",
      "2 Days in New York\n",
      "2 Days in New York\n",
      "2\n",
      "2\n",
      "1918\n",
      "54\n",
      "120\n",
      "7 Days in Havana\n",
      "7 Days in Havana\n",
      "7 Days in Havana\n",
      "9/11\n",
      "3\n",
      "99 Homes\n",
      "99 Homes\n",
      "21\n",
      "21 Jump Street\n",
      "21 Jump Street\n",
      "2\n",
      "71 Fragments of a Chronology of Chance\n",
      "71 Fragments of a Chronology of Chance\n",
      "71 Fragments of a Chronology of Chance\n",
      "71 Fragments of a Chronology of Chance\n",
      "71 Fragments of a Chronology of Chance\n",
      "71 Fragments of a Chronology of Chance\n",
      "1937\n",
      "1\n",
      "24 Hour Party People\n",
      "24 Hour Party People\n",
      "24 Hour Party People\n",
      "24 Hour Party People\n",
      "800 Bullets\n",
      "800 Bullets\n",
      "8 Heads in a Duffel Bag\n",
      "8 Heads in a Duffel Bag\n",
      "8 Heads in a Duffel Bag\n",
      "8 Heads in a Duffel Bag\n",
      "8 Heads in a Duffel Bag\n",
      "8 Heads in a Duffel Bag\n",
      "3\n",
      "3 Days to Kill\n",
      "3 Days to Kill\n",
      "3 Days to Kill\n",
      "52 Pick-Up\n",
      "52 Pick-Up\n",
      "3\n",
      "15th century\n",
      "15th century\n",
      "4\n",
      "9/11\n",
      "1920s\n",
      "12th century\n",
      "12th century\n",
      "60s\n",
      "13\n",
      "13 Tzameti\n",
      "21\n",
      "10\n",
      "10 Minutes\n",
      "2\n",
      "5 Centimeters Per Second\n",
      "5 Centimeters Per Second\n",
      "5 Centimeters Per Second\n",
      "5 Centimeters Per Second\n",
      "12\n",
      "71 Fragments of a Chronology of Chance\n",
      "71 Fragments of a Chronology of Chance\n",
      "71 Fragments of a Chronology of Chance\n",
      "71 Fragments of a Chronology of Chance\n",
      "71 Fragments of a Chronology of Chance\n",
      "71 Fragments of a Chronology of Chance\n",
      "7 Boxes\n",
      "7 Boxes\n",
      "4\n",
      "8½\n",
      "2\n",
      "1933\n",
      "711 Ocean Drive\n",
      "711 Ocean Drive\n",
      "1940\n",
      "3\n",
      "2\n",
      "3000 Miles to Graceland\n",
      "3000 Miles to Graceland\n",
      "3000 Miles to Graceland\n",
      "3000 Miles to Graceland\n",
      "2\n",
      "25 Watts\n",
      "25 Watts\n",
      "20,000 Days on Earth\n",
      "20,000 Days on Earth\n",
      "20,000 Days on Earth\n",
      "12\n",
      "12 O'Clock Boys\n",
      "1935\n",
      "976-EVIL\n",
      "7 Days\n",
      "7 Days\n",
      "2\n",
      "100 Feet\n",
      "100 Feet\n",
      "40 Pounds of Trouble\n",
      "40 Pounds of Trouble\n",
      "40 Pounds of Trouble\n",
      "40 Pounds of Trouble\n",
      "20 Million Miles to Earth\n",
      "20 Million Miles to Earth\n",
      "20 Million Miles to Earth\n",
      "20 Million Miles to Earth\n",
      "1\n",
      "28 Days\n",
      "28 Days\n",
      "2012\n",
      "2\n",
      "51\n",
      "11 Harrowhouse\n",
      "11 Harrowhouse\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "dir_str = \"../movieqa/questions/wiki_entities/entities\"\n",
    "directory = os.fsencode(dir_str)\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    filepath = dir_str + \"/\" + filename\n",
    "    \n",
    "    rawInput = open(filepath, 'r')\n",
    "    lines = []    \n",
    "    actual = rawInput.readline()\n",
    "    while actual != \"\":\n",
    "        lines.append(actual.rstrip('\\n'))\n",
    "        actual = rawInput.readline()\n",
    "    \n",
    "    # Create the data dict to generate the dataframe\n",
    "    data = { \"question\": [], \"entities\": [] }\n",
    "    for line in lines:\n",
    "        question, entities = line.split(\"\\t\")\n",
    "        data[\"question\"].append(str(question))\n",
    "        data[\"entities\"].append(eval(entities))\n",
    "    \n",
    "    # Get the entity name from the filename\n",
    "    entity_name = filename.split(\"_\")[2]\n",
    "    \n",
    "    for i in range(len(data[\"entities\"])):\n",
    "        tokens = data[\"entities\"][i]\n",
    "        isBegin = True\n",
    "        for j in range(len(tokens)):\n",
    "            token = tokens[j]\n",
    "            if token[0].isupper() or (token[0].isnumeric() and token[0] != '0') or (entity_name == \"tag\" and token != \"movies\" and token != '0'): # Transform the tokens in .txt's into the entity tokens\n",
    "                if (token[0].isnumeric() and token[0] != '0'): print(token)\n",
    "                if isBegin:\n",
    "                    tokens[j] = \"B-\" + entity_name\n",
    "                    isBegin = False\n",
    "                else:\n",
    "                    tokens[j] = \"I-\" + entity_name\n",
    "            elif token[0].islower(): # Remove other enitities\n",
    "                tokens[j] = '0'\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(\"./datasets/\" + filename[:-4] + \".csv\", index_label=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea37ccd",
   "metadata": {},
   "source": [
    "Concat the .csv's and generate the final .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fa015b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_str = \"./datasets/\"\n",
    "directory = os.fsencode(dir_str)\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    filepath = dir_str + \"/\" + filename\n",
    "    \n",
    "    df = pd.read_csv(filepath)\n",
    "    dfs.append(df)\n",
    "        \n",
    "dataset = pd.concat(dfs)\n",
    "# dataset = dataset.drop(columns=[\"Unnamed: 0\"])\n",
    "dataset.to_csv(\"./datasets/entities.csv\", index_label=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7414facb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>who's the writer of Experiment Perilous</td>\n",
       "      <td>['0', '0', '0', '0', 'B-movie', 'I-movie']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>who's the writer of Games</td>\n",
       "      <td>['0', '0', '0', '0', 'B-movie']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>which person wrote The Wolf Man</td>\n",
       "      <td>['0', '0', '0', 'B-movie', 'I-movie', 'I-movie']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who is the writer of the film Sweet Charity</td>\n",
       "      <td>['0', '0', '0', '0', '0', '0', '0', 'B-movie',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who was the writer of Extract</td>\n",
       "      <td>['0', '0', '0', '0', '0', 'B-movie']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      question  \\\n",
       "0      who's the writer of Experiment Perilous   \n",
       "1                    who's the writer of Games   \n",
       "2              which person wrote The Wolf Man   \n",
       "3  who is the writer of the film Sweet Charity   \n",
       "4                who was the writer of Extract   \n",
       "\n",
       "                                            entities  \n",
       "0         ['0', '0', '0', '0', 'B-movie', 'I-movie']  \n",
       "1                    ['0', '0', '0', '0', 'B-movie']  \n",
       "2   ['0', '0', '0', 'B-movie', 'I-movie', 'I-movie']  \n",
       "3  ['0', '0', '0', '0', '0', '0', '0', 'B-movie',...  \n",
       "4               ['0', '0', '0', '0', '0', 'B-movie']  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6312eca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
